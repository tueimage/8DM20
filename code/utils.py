import random

import numpy as np
import SimpleITK as sitk
import torch
import torch.nn as nn
import torchvision.transforms as transforms


class ProstateMRDataset(torch.utils.data.Dataset):
    """Dataset containing prostate MR images.

    Parameters
    ----------
    paths : list[Path]
        paths to the patient data
    img_size : list[int]
        size of images to be interpolated to
    """

    def __init__(self, paths, img_size, valid=False):
        self.mr_image_list = []
        self.mask_list = []
        # load images
        self.no_slices = 24
        for path in paths:
            im = sitk.GetArrayFromImage(sitk.ReadImage(path / "t2.nii.gz")).astype(
                np.int32
            )
            Ns = im.shape[0]
            self.mr_image_list.append(
                sitk.GetArrayFromImage(sitk.ReadImage(path / "t2.nii.gz")).astype(
                    np.int32
                )[Ns // 2 - self.no_slices // 2 : Ns // 2 + self.no_slices // 2, ...]
            )
            self.mask_list.append(
                sitk.GetArrayFromImage(
                    sitk.ReadImage(path / "t2_anatomy_reader1.nii.gz")
                ).astype(np.int32)[
                    Ns // 2 - self.no_slices // 2 : Ns // 2 + self.no_slices // 2, ...
                ]
            )

        # number of patients and slices in the dataset
        self.no_patients = len(self.mr_image_list)

        if valid:
            self.img_transform = transforms.Compose(
                [
                    transforms.ToPILImage(mode="I"),
                    # transforms.CenterCrop(256),
                    transforms.Resize(img_size),
                    transforms.ToTensor(),
                ]
            )
        else:
            # transforms to resize images
            self.img_transform = transforms.Compose(
                [
                    transforms.ToPILImage(mode="I"),
                    # transforms.CenterCrop(256),
                    transforms.Resize(img_size),
                    transforms.ToTensor(),
                ]
            )

        self.train_data_mean = 287
        self.train_data_std = 212
        self.norm_transform = transforms.Normalize(
            self.train_data_mean, self.train_data_std
        )

    def __len__(self):
        """Returns length of dataset"""
        return self.no_patients * self.no_slices

    def __getitem__(self, index):
        """Returns the preprocessing MR image and corresponding segementation
        for a given index.

        Parameters
        ----------
        index : int
            index of the image/segmentation in dataset
        """

        # compute which slice an index corresponds to
        patient = index // self.no_slices
        the_slice = index - (patient * self.no_slices)

        seed = np.random.randint(2147483647)  # make a seed with numpy generator
        random.seed(seed)
        torch.manual_seed(seed)

        x = self.norm_transform(
            self.img_transform(self.mr_image_list[patient][the_slice, ...]).float()
        )
        random.seed(seed)
        torch.manual_seed(seed)
        y = self.img_transform(
            (self.mask_list[patient][the_slice, ...] > 0).astype(np.int32)
        )
        return x, y


class DiceBCELoss(nn.Module):
    """Loss function, computed as the sum of Dice score and binary cross-entropy.

    Notes
    -----
    This loss assumes that the inputs are logits (i.e., the outputs of a linear layer),
    and that the targets are integer values that represent the correct class labels.
    """

    def __init__(self):
        super(DiceBCELoss, self).__init__()

    def forward(self, outputs, targets, smooth=1):
        """Calculates segmentation loss for training

        Parameters
        ----------
        outputs : torch.Tensor
            predictions of segmentation model
        targets : torch.Tensor
            ground-truth labels
        smooth : float
            smooth parameter for dice score avoids division by zero, by default 1

        Returns
        -------
        float
            the sum of the dice loss and binary cross-entropy
        """
        outputs = torch.sigmoid(outputs)

        # flatten label and prediction tensors
        outputs = outputs.view(-1)
        targets = targets.view(-1)

        # compute Dice
        intersection = (outputs * targets).sum()
        dice_loss = 1 - (2.0 * intersection + smooth) / (
            outputs.sum() + targets.sum() + smooth
        )
        BCE = nn.functional.binary_cross_entropy(outputs, targets, reduction="mean")

        return BCE + dice_loss
